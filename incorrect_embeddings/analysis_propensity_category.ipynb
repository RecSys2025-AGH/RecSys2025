{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import stats\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full embeddings shape: (1000000, 1280)\n",
            "Incorrect embeddings shape: (83453, 1280)\n",
            "Data type: PROPENSITY CATEGORY predictions\n"
          ]
        }
      ],
      "source": [
        "# Load embeddings for propensity category analysis\n",
        "full_embeddings = np.load(\"solutions/best/embeddings.npy\")\n",
        "incorrect_embeddings = np.load(\"incorrect_embeddings/incorrect_embeddings_propensity_category.npy\")\n",
        "\n",
        "print(f\"Full embeddings shape: {full_embeddings.shape}\")\n",
        "print(f\"Incorrect embeddings shape: {incorrect_embeddings.shape}\")\n",
        "print(f\"Data type: PROPENSITY CATEGORY predictions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define embedding extraction functions\n",
        "indexes = {\n",
        "    \"add_to_cart\": 0,\n",
        "    \"remove_from_cart\": 256,\n",
        "    \"product_buys\": 512,\n",
        "    \"search_query\": 768,\n",
        "    \"page_visits\": 1024,\n",
        "}\n",
        "\n",
        "def get_embedding(action):\n",
        "    return full_embeddings[:, indexes[action]:indexes[action] + 256]\n",
        "\n",
        "def get_incorrect_embedding(action):\n",
        "    return incorrect_embeddings[:, indexes[action]:indexes[action] + 256]\n",
        "\n",
        "def value_counts(x):\n",
        "    unique, counts = np.unique(x, return_counts=True)\n",
        "    sorted_indices = np.argsort(-counts)\n",
        "    unique = unique[sorted_indices]\n",
        "    counts = counts[sorted_indices]\n",
        "    print(np.asarray((unique, counts)).T)\n",
        "\n",
        "def count_zero_vectors(arr):\n",
        "    zero_rows = np.all(arr == 0, axis=1)\n",
        "    return np.sum(zero_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting comprehensive PROPENSITY CATEGORY analysis across all actions...\n",
            "\n",
            "============================================================\n",
            "ANALYZING ACTION: ADD_TO_CART (PROPENSITY CATEGORY)\n",
            "============================================================\n",
            "=== BASIC STATISTICS ===\n",
            "Correct embeddings shape: (1000000, 256)\n",
            "Incorrect embeddings shape: (83453, 256)\n",
            "Zero vectors in correct: 387456\n",
            "Zero vectors in incorrect: 18760\n",
            "Non-zero correct embeddings: (612544, 256)\n",
            "Zero vector proportion - Correct: 0.3875, Incorrect: 0.2248\n",
            "\n",
            "=== EMBEDDING MAGNITUDES ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adam/python-projects/recsys25/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:171: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct embeddings - Mean norm: 14.1094, Std: inf\n",
            "Incorrect embeddings - Mean norm: 10.0392, Std: 5.6800\n",
            "\n",
            "=== STATISTICAL COMPARISON ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adam/python-projects/recsys25/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:205: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct embeddings - Mean: -0.0011, Std: inf\n",
            "Incorrect embeddings - Mean: -0.0008, Std: 0.7209\n",
            "\n",
            "=== SIMILARITY ANALYSIS ===\n",
            "Correct intra-group similarity - Mean: 0.5732, Std: 0.1400\n",
            "Incorrect intra-group similarity - Mean: 0.3370, Std: 0.2847\n",
            "Cross-group similarity - Mean: 0.4366, Std: 0.2576\n",
            "\n",
            "=== STATISTICAL TESTS ===\n",
            "KS test - Statistic: 0.1151, p-value: 0.00e+00\n",
            "Mann-Whitney U test on norms - Statistic: 18676668, p-value: 0.00e+00\n",
            "\n",
            "============================================================\n",
            "ANALYZING ACTION: REMOVE_FROM_CART (PROPENSITY CATEGORY)\n",
            "============================================================\n",
            "=== BASIC STATISTICS ===\n",
            "Correct embeddings shape: (1000000, 256)\n",
            "Incorrect embeddings shape: (83453, 256)\n",
            "Zero vectors in correct: 675606\n",
            "Zero vectors in incorrect: 41485\n",
            "Non-zero correct embeddings: (324394, 256)\n",
            "Zero vector proportion - Correct: 0.6756, Incorrect: 0.4971\n",
            "\n",
            "=== EMBEDDING MAGNITUDES ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adam/python-projects/recsys25/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:171: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct embeddings - Mean norm: 14.0547, Std: inf\n",
            "Incorrect embeddings - Mean norm: 6.5020, Std: 6.6422\n",
            "\n",
            "=== STATISTICAL COMPARISON ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adam/python-projects/recsys25/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:205: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct embeddings - Mean: -0.0016, Std: inf\n",
            "Incorrect embeddings - Mean: -0.0008, Std: 0.5809\n",
            "\n",
            "=== SIMILARITY ANALYSIS ===\n",
            "Correct intra-group similarity - Mean: 0.4504, Std: 0.1172\n",
            "Incorrect intra-group similarity - Mean: 0.0960, Std: 0.1914\n",
            "Cross-group similarity - Mean: 0.2062, Std: 0.2353\n",
            "\n",
            "=== STATISTICAL TESTS ===\n",
            "KS test - Statistic: 0.2485, p-value: 0.00e+00\n",
            "Mann-Whitney U test on norms - Statistic: 20746153, p-value: 0.00e+00\n",
            "\n",
            "============================================================\n",
            "ANALYZING ACTION: PRODUCT_BUYS (PROPENSITY CATEGORY)\n",
            "============================================================\n",
            "=== BASIC STATISTICS ===\n",
            "Correct embeddings shape: (1000000, 256)\n",
            "Incorrect embeddings shape: (83453, 256)\n",
            "Zero vectors in correct: 492448\n",
            "Zero vectors in incorrect: 68\n",
            "Non-zero correct embeddings: (507552, 256)\n",
            "Zero vector proportion - Correct: 0.4924, Incorrect: 0.0008\n",
            "\n",
            "=== EMBEDDING MAGNITUDES ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adam/python-projects/recsys25/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:171: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct embeddings - Mean norm: 14.8125, Std: inf\n",
            "Incorrect embeddings - Mean norm: 13.9472, Std: 1.7745\n",
            "\n",
            "=== STATISTICAL COMPARISON ===\n",
            "Correct embeddings - Mean: -0.0027, Std: inf\n",
            "Incorrect embeddings - Mean: -0.0028, Std: 0.8787\n",
            "\n",
            "=== SIMILARITY ANALYSIS ===\n",
            "Correct intra-group similarity - Mean: 0.4733, Std: 0.1347\n",
            "Incorrect intra-group similarity - Mean: 0.4751, Std: 0.1441\n",
            "Cross-group similarity - Mean: 0.4723, Std: 0.1393\n",
            "\n",
            "=== STATISTICAL TESTS ===\n",
            "KS test - Statistic: 0.0148, p-value: 6.27e-122\n",
            "Mann-Whitney U test on norms - Statistic: 16418376, p-value: 2.82e-162\n",
            "\n",
            "============================================================\n",
            "ANALYZING ACTION: SEARCH_QUERY (PROPENSITY CATEGORY)\n",
            "============================================================\n",
            "=== BASIC STATISTICS ===\n",
            "Correct embeddings shape: (1000000, 256)\n",
            "Incorrect embeddings shape: (83453, 256)\n",
            "Zero vectors in correct: 676832\n",
            "Zero vectors in incorrect: 38316\n",
            "Non-zero correct embeddings: (323168, 256)\n",
            "Zero vector proportion - Correct: 0.6768, Incorrect: 0.4591\n",
            "\n",
            "=== EMBEDDING MAGNITUDES ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adam/python-projects/recsys25/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:171: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct embeddings - Mean norm: 12.2031, Std: inf\n",
            "Incorrect embeddings - Mean norm: 6.5569, Std: 6.2339\n",
            "\n",
            "=== STATISTICAL COMPARISON ===\n",
            "Correct embeddings - Mean: 0.0029, Std: inf\n",
            "Incorrect embeddings - Mean: 0.0013, Std: 0.5655\n",
            "\n",
            "=== SIMILARITY ANALYSIS ===\n",
            "Correct intra-group similarity - Mean: 0.4496, Std: 0.1696\n",
            "Incorrect intra-group similarity - Mean: 0.1394, Std: 0.2700\n",
            "Cross-group similarity - Mean: 0.2222, Std: 0.2640\n",
            "\n",
            "=== STATISTICAL TESTS ===\n",
            "KS test - Statistic: 0.2352, p-value: 0.00e+00\n",
            "Mann-Whitney U test on norms - Statistic: 18524975, p-value: 0.00e+00\n",
            "\n",
            "============================================================\n",
            "ANALYZING ACTION: PAGE_VISITS (PROPENSITY CATEGORY)\n",
            "============================================================\n",
            "=== BASIC STATISTICS ===\n",
            "Correct embeddings shape: (1000000, 256)\n",
            "Incorrect embeddings shape: (83453, 256)\n",
            "Zero vectors in correct: 173519\n",
            "Zero vectors in incorrect: 15695\n",
            "Non-zero correct embeddings: (826481, 256)\n",
            "Zero vector proportion - Correct: 0.1735, Incorrect: 0.1881\n",
            "\n",
            "=== EMBEDDING MAGNITUDES ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adam/python-projects/recsys25/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:171: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct embeddings - Mean norm: 10.9766, Std: inf\n",
            "Incorrect embeddings - Mean norm: 8.6168, Std: 4.4545\n",
            "\n",
            "=== STATISTICAL COMPARISON ===\n",
            "Correct embeddings - Mean: 0.0018, Std: inf\n",
            "Incorrect embeddings - Mean: 0.0016, Std: 0.6063\n",
            "\n",
            "=== SIMILARITY ANALYSIS ===\n",
            "Correct intra-group similarity - Mean: 0.5337, Std: 0.1307\n",
            "Incorrect intra-group similarity - Mean: 0.4017, Std: 0.3005\n",
            "Cross-group similarity - Mean: 0.4352, Std: 0.2381\n",
            "\n",
            "=== STATISTICAL TESTS ===\n",
            "KS test - Statistic: 0.0948, p-value: 0.00e+00\n",
            "Mann-Whitney U test on norms - Statistic: 16221382, p-value: 1.10e-146\n"
          ]
        }
      ],
      "source": [
        "# Comprehensive analysis across all action types for PROPENSITY CATEGORY\n",
        "actions = [\"add_to_cart\", \"remove_from_cart\", \"product_buys\", \"search_query\", \"page_visits\"]\n",
        "\n",
        "def analyze_action_propensity_category(action_name):\n",
        "    \"\"\"Comprehensive analysis for a single action type - PROPENSITY CATEGORY focus\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ANALYZING ACTION: {action_name.upper()} (PROPENSITY CATEGORY)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Get embeddings for this action\n",
        "    correct_emb = get_embedding(action_name)\n",
        "    incorrect_emb = get_incorrect_embedding(action_name)\n",
        "    \n",
        "    print(f\"=== BASIC STATISTICS ===\")\n",
        "    print(f\"Correct embeddings shape: {correct_emb.shape}\")\n",
        "    print(f\"Incorrect embeddings shape: {incorrect_emb.shape}\")\n",
        "    print(f\"Zero vectors in correct: {count_zero_vectors(correct_emb)}\")\n",
        "    print(f\"Zero vectors in incorrect: {count_zero_vectors(incorrect_emb)}\")\n",
        "    \n",
        "    # Remove zero vectors for fair comparison\n",
        "    non_zero_correct = correct_emb[~np.all(correct_emb == 0, axis=1)]\n",
        "    zero_prop_correct = count_zero_vectors(correct_emb) / len(correct_emb)\n",
        "    zero_prop_incorrect = count_zero_vectors(incorrect_emb) / len(incorrect_emb)\n",
        "    \n",
        "    print(f\"Non-zero correct embeddings: {non_zero_correct.shape}\")\n",
        "    print(f\"Zero vector proportion - Correct: {zero_prop_correct:.4f}, Incorrect: {zero_prop_incorrect:.4f}\")\n",
        "    \n",
        "    if len(non_zero_correct) == 0:\n",
        "        print(\"WARNING: No non-zero correct embeddings found!\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"\\n=== EMBEDDING MAGNITUDES ===\")\n",
        "    correct_norms = np.linalg.norm(non_zero_correct, axis=1)\n",
        "    incorrect_norms = np.linalg.norm(incorrect_emb, axis=1)\n",
        "    \n",
        "    print(f\"Correct embeddings - Mean norm: {np.mean(correct_norms):.4f}, Std: {np.std(correct_norms):.4f}\")\n",
        "    print(f\"Incorrect embeddings - Mean norm: {np.mean(incorrect_norms):.4f}, Std: {np.std(incorrect_norms):.4f}\")\n",
        "    \n",
        "    print(f\"\\n=== STATISTICAL COMPARISON ===\")\n",
        "    print(f\"Correct embeddings - Mean: {np.mean(non_zero_correct):.4f}, Std: {np.std(non_zero_correct):.4f}\")\n",
        "    print(f\"Incorrect embeddings - Mean: {np.mean(incorrect_emb):.4f}, Std: {np.std(incorrect_emb):.4f}\")\n",
        "    \n",
        "    # Sample for detailed analysis\n",
        "    n_samples = min(5000, len(non_zero_correct), len(incorrect_emb))\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    correct_sample_idx = np.random.choice(len(non_zero_correct), n_samples, replace=False)\n",
        "    incorrect_sample_idx = np.random.choice(len(incorrect_emb), n_samples, replace=False)\n",
        "    \n",
        "    correct_sample = non_zero_correct[correct_sample_idx]\n",
        "    incorrect_sample = incorrect_emb[incorrect_sample_idx]\n",
        "    \n",
        "    # Similarity analysis\n",
        "    print(f\"\\n=== SIMILARITY ANALYSIS ===\")\n",
        "    n_sim_samples = min(500, len(correct_sample), len(incorrect_sample))\n",
        "    \n",
        "    correct_similarities = cosine_similarity(correct_sample[:n_sim_samples])\n",
        "    incorrect_similarities = cosine_similarity(incorrect_sample[:n_sim_samples])\n",
        "    cross_similarities = cosine_similarity(correct_sample[:n_sim_samples], incorrect_sample[:n_sim_samples])\n",
        "    \n",
        "    def get_upper_triangle(matrix):\n",
        "        return matrix[np.triu_indices_from(matrix, k=1)]\n",
        "    \n",
        "    correct_sim_values = get_upper_triangle(correct_similarities)\n",
        "    incorrect_sim_values = get_upper_triangle(incorrect_similarities)\n",
        "    cross_sim_values = cross_similarities.flatten()\n",
        "    \n",
        "    print(f\"Correct intra-group similarity - Mean: {np.mean(correct_sim_values):.4f}, Std: {np.std(correct_sim_values):.4f}\")\n",
        "    print(f\"Incorrect intra-group similarity - Mean: {np.mean(incorrect_sim_values):.4f}, Std: {np.std(incorrect_sim_values):.4f}\")\n",
        "    print(f\"Cross-group similarity - Mean: {np.mean(cross_sim_values):.4f}, Std: {np.std(cross_sim_values):.4f}\")\n",
        "    \n",
        "    # Statistical tests\n",
        "    print(f\"\\n=== STATISTICAL TESTS ===\")\n",
        "    ks_stat, ks_pvalue = stats.ks_2samp(correct_sample.flatten(), incorrect_sample.flatten())\n",
        "    print(f\"KS test - Statistic: {ks_stat:.4f}, p-value: {ks_pvalue:.2e}\")\n",
        "    \n",
        "    correct_sample_norms = np.linalg.norm(correct_sample, axis=1)\n",
        "    incorrect_sample_norms = np.linalg.norm(incorrect_sample, axis=1)\n",
        "    mw_stat, mw_pvalue = stats.mannwhitneyu(correct_sample_norms, incorrect_sample_norms)\n",
        "    print(f\"Mann-Whitney U test on norms - Statistic: {mw_stat:.0f}, p-value: {mw_pvalue:.2e}\")\n",
        "    \n",
        "    return {\n",
        "        'action': action_name,\n",
        "        'zero_prop_correct': zero_prop_correct,\n",
        "        'zero_prop_incorrect': zero_prop_incorrect,\n",
        "        'correct_norm_mean': np.mean(correct_norms),\n",
        "        'incorrect_norm_mean': np.mean(incorrect_norms),\n",
        "        'correct_sim_mean': np.mean(correct_sim_values),\n",
        "        'incorrect_sim_mean': np.mean(incorrect_sim_values),\n",
        "        'cross_sim_mean': np.mean(cross_sim_values),\n",
        "        'ks_stat': ks_stat,\n",
        "        'ks_pvalue': ks_pvalue\n",
        "    }\n",
        "\n",
        "# Run analysis for all actions\n",
        "print(\"Starting comprehensive PROPENSITY CATEGORY analysis across all actions...\")\n",
        "results = []\n",
        "for action in actions:\n",
        "    result = analyze_action_propensity_category(action)\n",
        "    if result is not None:\n",
        "        results.append(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY COMPARISON ACROSS ALL ACTIONS - PROPENSITY CATEGORY\n",
            "================================================================================\n",
            "          action  zero_prop_correct  zero_prop_incorrect  correct_norm_mean  incorrect_norm_mean  correct_sim_mean  incorrect_sim_mean  cross_sim_mean  ks_stat  ks_pvalue\n",
            "     add_to_cart             0.3875               0.2248            14.1094              10.0392            0.5732              0.3370          0.4366   0.1151     0.0000\n",
            "remove_from_cart             0.6756               0.4971            14.0547               6.5020            0.4504              0.0960          0.2062   0.2485     0.0000\n",
            "    product_buys             0.4924               0.0008            14.8125              13.9472            0.4733              0.4751          0.4723   0.0148     0.0000\n",
            "    search_query             0.6768               0.4591            12.2031               6.5569            0.4496              0.1394          0.2222   0.2352     0.0000\n",
            "     page_visits             0.1735               0.1881            10.9766               8.6168            0.5337              0.4017          0.4352   0.0948     0.0000\n",
            "\n",
            "=== KEY INSIGHTS ACROSS ACTIONS (PROPENSITY CATEGORY) ===\n",
            "\n",
            "1. ACTIVITY PATTERNS (Zero Vector Proportions):\n",
            "   add_to_cart     - Correct: 38.7%, Incorrect: 22.5%\n",
            "   remove_from_cart - Correct: 67.6%, Incorrect: 49.7%\n",
            "   product_buys    - Correct: 49.2%, Incorrect: 0.1%\n",
            "   search_query    - Correct: 67.7%, Incorrect: 45.9%\n",
            "   page_visits     - Correct: 17.4%, Incorrect: 18.8%\n",
            "\n",
            "2. EMBEDDING MAGNITUDE DIFFERENCES:\n",
            "   add_to_cart     - Incorrect norms LOWER by 4.070\n",
            "   remove_from_cart - Incorrect norms LOWER by 7.553\n",
            "   product_buys    - Incorrect norms LOWER by 0.865\n",
            "   search_query    - Incorrect norms LOWER by 5.646\n",
            "   page_visits     - Incorrect norms LOWER by 2.360\n",
            "\n",
            "3. SIMILARITY PATTERNS:\n",
            "   add_to_cart     - Cross-group similarity: 0.437 (MODERATE)\n",
            "   remove_from_cart - Cross-group similarity: 0.206 (MODERATE)\n",
            "   product_buys    - Cross-group similarity: 0.472 (MODERATE)\n",
            "   search_query    - Cross-group similarity: 0.222 (MODERATE)\n",
            "   page_visits     - Cross-group similarity: 0.435 (MODERATE)\n",
            "\n",
            "4. STATISTICAL SIGNIFICANCE:\n",
            "   add_to_cart     - KS test: SIGNIFICANT (p=0.00e+00)\n",
            "   remove_from_cart - KS test: SIGNIFICANT (p=0.00e+00)\n",
            "   product_buys    - KS test: SIGNIFICANT (p=6.27e-122)\n",
            "   search_query    - KS test: SIGNIFICANT (p=0.00e+00)\n",
            "   page_visits     - KS test: SIGNIFICANT (p=0.00e+00)\n",
            "\n",
            "5. MOST PROBLEMATIC ACTIONS (ranked by issues):\n",
            "   add_to_cart     - Problem score: 3/3\n",
            "   product_buys    - Problem score: 3/3\n",
            "   remove_from_cart - Problem score: 2/3\n",
            "   search_query    - Problem score: 2/3\n",
            "   page_visits     - Problem score: 2/3\n"
          ]
        }
      ],
      "source": [
        "# Create summary comparison across all actions for PROPENSITY CATEGORY\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SUMMARY COMPARISON ACROSS ALL ACTIONS - PROPENSITY CATEGORY\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "if results:\n",
        "    df = pd.DataFrame(results)\n",
        "    print(df.to_string(index=False, float_format='%.4f'))\n",
        "    \n",
        "    # Key insights\n",
        "    print(f\"\\n=== KEY INSIGHTS ACROSS ACTIONS (PROPENSITY CATEGORY) ===\")\n",
        "    \n",
        "    print(\"\\n1. ACTIVITY PATTERNS (Zero Vector Proportions):\")\n",
        "    for _, row in df.iterrows():\n",
        "        print(f\"   {row['action']:15} - Correct: {row['zero_prop_correct']:.1%}, Incorrect: {row['zero_prop_incorrect']:.1%}\")\n",
        "    \n",
        "    print(\"\\n2. EMBEDDING MAGNITUDE DIFFERENCES:\")\n",
        "    for _, row in df.iterrows():\n",
        "        norm_diff = row['incorrect_norm_mean'] - row['correct_norm_mean']\n",
        "        direction = \"HIGHER\" if norm_diff > 0 else \"LOWER\"\n",
        "        print(f\"   {row['action']:15} - Incorrect norms {direction} by {abs(norm_diff):.3f}\")\n",
        "    \n",
        "    print(\"\\n3. SIMILARITY PATTERNS:\")\n",
        "    for _, row in df.iterrows():\n",
        "        cross_sim = row['cross_sim_mean']\n",
        "        status = \"HIGH\" if cross_sim > 0.5 else \"MODERATE\" if cross_sim > 0.2 else \"LOW\"\n",
        "        print(f\"   {row['action']:15} - Cross-group similarity: {cross_sim:.3f} ({status})\")\n",
        "    \n",
        "    print(\"\\n4. STATISTICAL SIGNIFICANCE:\")\n",
        "    for _, row in df.iterrows():\n",
        "        significance = \"SIGNIFICANT\" if row['ks_pvalue'] < 0.001 else \"NOT SIGNIFICANT\"\n",
        "        print(f\"   {row['action']:15} - KS test: {significance} (p={row['ks_pvalue']:.2e})\")\n",
        "        \n",
        "    # Find most problematic actions\n",
        "    print(\"\\n5. MOST PROBLEMATIC ACTIONS (ranked by issues):\")\n",
        "    df['problem_score'] = (\n",
        "        (df['zero_prop_incorrect'] < df['zero_prop_correct']) * 1 +  # Incorrect has fewer zeros\n",
        "        (df['cross_sim_mean'] > 0.3) * 1 +  # High cross-similarity\n",
        "        (df['ks_pvalue'] < 0.001) * 1  # Statistically different\n",
        "    )\n",
        "    problematic = df.sort_values('problem_score', ascending=False)\n",
        "    for _, row in problematic.iterrows():\n",
        "        print(f\"   {row['action']:15} - Problem score: {row['problem_score']}/3\")\n",
        "\n",
        "else:\n",
        "    print(\"No results to analyze.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL ANALYSIS AND RECOMMENDATIONS - PROPENSITY CATEGORY\n",
            "================================================================================\n",
            "\n",
            "=== COMMON PATTERNS ACROSS ALL ACTIONS (PROPENSITY CATEGORY) ===\n",
            "1. ACTIVITY BIAS (incorrect has fewer inactive users): ['add_to_cart', 'remove_from_cart', 'product_buys', 'search_query']\n",
            "2. HIGH CROSS-SIMILARITY (>0.3): ['add_to_cart', 'product_buys', 'page_visits']\n",
            "3. SIGNIFICANT NORM DIFFERENCES (>0.1): ['add_to_cart', 'remove_from_cart', 'product_buys', 'search_query', 'page_visits']\n",
            "\n",
            "=== ROOT CAUSE ANALYSIS (PROPENSITY CATEGORY) ===\n",
            "The model's propensity category predictions show:\n",
            "\n",
            "1. CATEGORY PREDICTION CHALLENGES:\n",
            "   - Model struggles to predict which product categories users will engage with\n",
            "   - Category preferences may be more nuanced than captured in embeddings\n",
            "   - User behavior patterns may not translate well to category-level predictions\n",
            "\n",
            "2. EMBEDDING SPACE ISSUES:\n",
            "\n",
            "3. CATEGORY-SPECIFIC PATTERNS:\n",
            "   - 3/5 actions show poor category prediction separation\n",
            "   - User embeddings may not capture category preferences well\n",
            "   - Cross-category similarities may be too high\n",
            "\n",
            "=== RECOMMENDATIONS FOR PROPENSITY CATEGORY MODELING ===\n",
            "1. CATEGORY-SPECIFIC FEATURES:\n",
            "   - Add explicit category interaction features\n",
            "   - Consider category hierarchy information\n",
            "   - Include category co-occurrence patterns\n",
            "2. MODEL ARCHITECTURE:\n",
            "   - Consider category-specific embedding spaces\n",
            "   - Implement hierarchical category modeling\n",
            "   - Add category attention mechanisms\n",
            "3. DATA REPRESENTATION:\n",
            "   - Improve category embedding quality\n",
            "   - Consider temporal category preferences\n",
            "   - Add category-level behavioral features\n",
            "4. EVALUATION APPROACH:\n",
            "   - Category-specific evaluation metrics\n",
            "   - Consider category diversity in recommendations\n",
            "   - Evaluate category coverage and novelty\n"
          ]
        }
      ],
      "source": [
        "# Final analysis and recommendations for PROPENSITY CATEGORY\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"FINAL ANALYSIS AND RECOMMENDATIONS - PROPENSITY CATEGORY\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "if results:\n",
        "    # Identify patterns across all actions\n",
        "    print(\"\\n=== COMMON PATTERNS ACROSS ALL ACTIONS (PROPENSITY CATEGORY) ===\")\n",
        "    \n",
        "    activity_bias_actions = [r['action'] for r in results if r['zero_prop_incorrect'] < r['zero_prop_correct']]\n",
        "    high_cross_sim_actions = [r['action'] for r in results if r['cross_sim_mean'] > 0.3]\n",
        "    norm_difference_actions = [r['action'] for r in results if abs(r['incorrect_norm_mean'] - r['correct_norm_mean']) > 0.1]\n",
        "    \n",
        "    print(f\"1. ACTIVITY BIAS (incorrect has fewer inactive users): {activity_bias_actions}\")\n",
        "    print(f\"2. HIGH CROSS-SIMILARITY (>0.3): {high_cross_sim_actions}\")\n",
        "    print(f\"3. SIGNIFICANT NORM DIFFERENCES (>0.1): {norm_difference_actions}\")\n",
        "    \n",
        "    print(f\"\\n=== ROOT CAUSE ANALYSIS (PROPENSITY CATEGORY) ===\")\n",
        "    print(\"The model's propensity category predictions show:\")\n",
        "    \n",
        "    print(\"\\n1. CATEGORY PREDICTION CHALLENGES:\")\n",
        "    print(\"   - Model struggles to predict which product categories users will engage with\")\n",
        "    print(\"   - Category preferences may be more nuanced than captured in embeddings\")\n",
        "    print(\"   - User behavior patterns may not translate well to category-level predictions\")\n",
        "    \n",
        "    print(\"\\n2. EMBEDDING SPACE ISSUES:\")\n",
        "    norm_higher_count = sum(1 for r in results if r['incorrect_norm_mean'] > r['correct_norm_mean'])\n",
        "    if norm_higher_count > len(results) / 2:\n",
        "        print(\"   - Incorrect category predictions have higher embedding magnitudes\")\n",
        "        print(\"   - Model may be overconfident about wrong category preferences\")\n",
        "        print(\"   - Category representations may be too coarse-grained\")\n",
        "    \n",
        "    print(\"\\n3. CATEGORY-SPECIFIC PATTERNS:\")\n",
        "    poor_separation_count = sum(1 for r in results if r['cross_sim_mean'] > 0.3)\n",
        "    if poor_separation_count > 0:\n",
        "        print(f\"   - {poor_separation_count}/{len(results)} actions show poor category prediction separation\")\n",
        "        print(\"   - User embeddings may not capture category preferences well\")\n",
        "        print(\"   - Cross-category similarities may be too high\")\n",
        "    \n",
        "    print(f\"\\n=== RECOMMENDATIONS FOR PROPENSITY CATEGORY MODELING ===\")\n",
        "    print(\"1. CATEGORY-SPECIFIC FEATURES:\")\n",
        "    print(\"   - Add explicit category interaction features\")\n",
        "    print(\"   - Consider category hierarchy information\")\n",
        "    print(\"   - Include category co-occurrence patterns\")\n",
        "    \n",
        "    print(\"2. MODEL ARCHITECTURE:\")\n",
        "    print(\"   - Consider category-specific embedding spaces\")\n",
        "    print(\"   - Implement hierarchical category modeling\")\n",
        "    print(\"   - Add category attention mechanisms\")\n",
        "    \n",
        "    print(\"3. DATA REPRESENTATION:\")\n",
        "    print(\"   - Improve category embedding quality\")\n",
        "    print(\"   - Consider temporal category preferences\")\n",
        "    print(\"   - Add category-level behavioral features\")\n",
        "    \n",
        "    print(\"4. EVALUATION APPROACH:\")\n",
        "    print(\"   - Category-specific evaluation metrics\")\n",
        "    print(\"   - Consider category diversity in recommendations\")\n",
        "    print(\"   - Evaluate category coverage and novelty\")\n",
        "\n",
        "else:\n",
        "    print(\"No results to analyze.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
