{"cells":[{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"buys bert\n","\n","Automatically generated by Colab.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1wy_ovK0Hxdr-6AXlfS5CvjkBAm3wgPD8\n","\"\"\"\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import random\n","import torch\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import pickle\n","import torch\n","import tqdm\n","from torch import optim\n","from torch.utils.data import DataLoader, random_split\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Working on {DEVICE=}')\n","\n","import torch\n","from torch import nn\n","from dataclasses import dataclass\n","import numpy as np\n","\n","\n","# GPT said this is a professional way to do it\n","@dataclass\n","class BERT4RecConfig:\n","    # EmbeddingLayer\n","    vocab_size: int\n","    embedding_dim: int\n","    max_seq_len: int\n","    embedding_dropout: float\n","\n","    # Encoder\n","    num_layers: int\n","    num_heads: int\n","    hidden_dim: int\n","    encoder_dropout: float\n","\n","    # ProjectionHead\n","    projection_dim: int\n","\n","\n","class EmbeddingLayer(nn.Module):\n","    \"\"\"Item + positional embeddings with layer normalization and dropout\"\"\"\n","\n","    def __init__(self, vocab_size: int, embedding_dim: int, max_seq_len: int, dropout: float = 0.1):\n","        super().__init__()\n","        self.item_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.position_embeddings = nn.Embedding(max_seq_len, embedding_dim)\n","        self.layer_norm = nn.LayerNorm(embedding_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        self.vocab_size = vocab_size\n","\n","    def forward(self, x):\n","        positions = torch.arange(x.size(1), device=x.device).unsqueeze(0).expand_as(x)\n","        # print(x.max(), self.vocab_size, x.min())\n","        embeddings = self.item_embeddings(x) + self.position_embeddings(positions)\n","        embeddings = self.layer_norm(embeddings)\n","        return self.dropout(embeddings)\n","\n","\n","class Encoder(nn.Module):\n","    \"\"\"Transformer encoder. Wrapper for `torch.TransformerEncoderLayer`\"\"\"\n","\n","    def __init__(self, embedding_dim: int, num_layers: int, num_heads: int, hidden_dim: int,\n","                 dropout: float = 0.1) -> None:\n","        \"\"\"\n","\n","        Args:\n","            embedding_dim:\n","            num_layers:\n","            num_heads:\n","            hidden_dim:\n","            dropout:\n","\n","        Returns:\n","            None:\n","        \"\"\"\n","        super().__init__()\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=embedding_dim,\n","            nhead=num_heads,\n","            dim_feedforward=hidden_dim,\n","            dropout=dropout,\n","            activation=\"gelu\",\n","            batch_first=True,\n","        )\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","\n","    def forward(self, x, src_key_padding_mask=None):\n","        # x: [batch_size, seq_len, embedding_dim]\n","        return self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n","\n","\n","class ProjectionHead(nn.Module):\n","    \"\"\"Projection head\"\"\"\n","\n","    def __init__(self, embedding_dim: int, projection_dim: int, vocab_size: int):\n","        super().__init__()\n","        # transform + layer normalization\n","        self.projection = nn.Linear(embedding_dim, projection_dim)\n","        self.activation = nn.GELU()\n","        self.layer_norm = nn.LayerNorm(projection_dim)\n","\n","        # map to final logits\n","        self.decoder = nn.Linear(projection_dim, vocab_size, bias=False)\n","        self.bias = nn.Parameter(torch.zeros(vocab_size))\n","\n","    def forward(self, x):\n","        # x: [batch_size, seq_len, embedding_dim]\n","        proj = self.projection(x)\n","        proj = self.activation(proj)\n","        proj = self.layer_norm(proj)\n","        return self.decoder(proj) + self.bias\n","\n","\n","class BERT4Rec(nn.Module):\n","    \"\"\"BERT4Rec model from `https://arxiv.org/pdf/1904.06690` paper\"\"\"\n","\n","    def __init__(self, config: BERT4RecConfig):\n","        super().__init__()\n","        self.embedding = EmbeddingLayer(\n","            vocab_size=config.vocab_size,\n","            embedding_dim=config.embedding_dim,\n","            max_seq_len=config.max_seq_len,\n","            dropout=config.embedding_dropout,\n","        )\n","        self.encoder = Encoder(\n","            embedding_dim=config.embedding_dim,\n","            num_layers=config.num_layers,\n","            num_heads=config.num_heads,\n","            hidden_dim=config.hidden_dim,\n","            dropout=config.encoder_dropout,\n","        )\n","        self.projection = ProjectionHead(\n","            embedding_dim=config.embedding_dim,\n","            projection_dim=config.projection_dim,\n","            vocab_size=config.vocab_size,\n","        )\n","\n","        # weights sharing\n","        self.projection.decoder.weight = self.embedding.item_embeddings.weight\n","\n","    def forward(self, x, mask=None):\n","        x = torch.clamp(x, 0, self.embedding.vocab_size - 1)\n","        pad_mask = x.eq(0)\n","        x = self.embedding(x)\n","        x = self.encoder(x, src_key_padding_mask=pad_mask)\n","        x = self.projection(x)\n","        return x\n","\n","def masked_cross_entropy_loss(logits, labels, mask, eps=1e-8):\n","    logits = logits.view(-1, logits.size(-1))\n","    labels = labels.view(-1)\n","    mask = mask.view(-1).float()\n","\n","    loss = F.cross_entropy(logits, labels, reduction='none')\n","    masked_loss = loss * mask\n","    denom = mask.sum()\n","    return masked_loss.sum() / (denom + eps)\n","\n","\n","\n","def train_step(model, optimizer, batch, device=DEVICE):\n","    model.train()\n","    input_ids, labels, masked_pos = [x.to(device) for x in batch]  # all [B, L]\n","\n","    optimizer.zero_grad()\n","    logits = model(input_ids)  # [B, L, V]\n","    loss = masked_cross_entropy_loss(logits, labels, masked_pos)\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","\n","    return loss.item()\n","\n","\n","def validate_step(model, batch, top_k=10, device=DEVICE):\n","    model.eval()\n","    input_ids, labels, masked_pos = [x.to(device) for x in batch]\n","\n","    # Comprehensive validation\n","    vocab_size = model.embedding.item_embeddings.num_embeddings\n","\n","    if input_ids.max() >= vocab_size:\n","        print(f\"ERROR: Found index {input_ids.max().item()} >= vocab_size {vocab_size}\")\n","        print(f\"Problematic indices: {input_ids[input_ids >= vocab_size]}\")\n","        # Emergency fix: clamp to valid range\n","        input_ids = torch.clamp(input_ids, 0, vocab_size - 1)\n","\n","    if input_ids.min() < 0:\n","        print(f\"ERROR: Found negative index {input_ids.min().item()}\")\n","        input_ids = torch.clamp(input_ids, 0, vocab_size - 1)\n","\n","\n","    try:\n","        with torch.no_grad():\n","            logits = model(input_ids)\n","    except IndexError as e:\n","        print(f\"IndexError caught: {e}\")\n","        print(f\"Input stats: min={input_ids.min()}, max={input_ids.max()}, shape={input_ids.shape}\")\n","        return 0.0, 0.0, 0.0\n","\n","    # Rest of your validation logic...\n","    masked_logits = logits[masked_pos.bool()]\n","    masked_labels = labels[masked_pos.bool()]\n","\n","    if len(masked_logits) == 0:\n","        return 0.0, 0.0, 0.0\n","\n","    loss = F.cross_entropy(masked_logits, masked_labels, reduction='mean').item()\n","\n","    _, topk = masked_logits.topk(top_k, dim=-1)\n","    hits = (topk == masked_labels.unsqueeze(1)).float()\n","    hr = hits.any(dim=1).float().mean().item()\n","    ndcg = (hits / torch.log2(torch.arange(2, top_k + 2, device=hits.device).float())).sum(dim=1).mean().item()\n","\n","    return loss, hr, ndcg\n","\n","\n","\n","def mask_sequence(seq, mask_token_id, vocab_size, mask_prob=0.15, pad_token_id=0):\n","    \"\"\"\n","    Function takes a user sequence and randomly selects items to mask.\n","    Returns:\n","        - input_ids: modified sequence with [MASK] and others.\n","        - labels: target items only in masked positions (0 elsewhere).\n","        - masked_pos: binary mask of masked locations.\n","    \"\"\"\n","    input_ids = seq.copy()\n","    labels = [0] * len(seq)\n","    masked_pos = [0] * len(seq)\n","    # mask_prob = 0.5\n","\n","    for i in range(len(seq)):\n","        if seq[i] == pad_token_id:\n","            continue\n","        if random.random() < mask_prob:\n","            masked_pos[i] = 1\n","            labels[i] = seq[i]\n","            rand = random.random()\n","            if rand < 0.8:\n","                input_ids[i] = mask_token_id\n","            elif rand < 0.9:\n","                input_ids[i] = random.randint(1, vocab_size - 1)  # avoid pad token\n","            else:\n","                pass  # leave unchanged\n","    return input_ids, labels, masked_pos\n","\n","\n","def collate_fn(batch, mask_token_id, vocab_size, pad_token_id=0, max_len=None):\n","    \"\"\"\n","    Pads sequences to same length, converts everything to tensors.\n","    batch: list of sequences (list of item IDs)\n","    \"\"\"\n","    input_ids, labels, masked_pos = [], [], []\n","\n","    for seq in batch:\n","        if max_len is not None:\n","            seq = seq[-max_len:]  # truncate if needed\n","\n","        inp, lab, msk = mask_sequence(seq, mask_token_id, vocab_size, pad_token_id=pad_token_id)\n","        input_ids.append(torch.tensor(inp))\n","        labels.append(torch.tensor(lab))\n","        masked_pos.append(torch.tensor(msk))\n","\n","    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=pad_token_id)\n","    labels = pad_sequence(labels, batch_first=True, padding_value=0)\n","    masked_pos = pad_sequence(masked_pos, batch_first=True, padding_value=0)\n","\n","    return input_ids, labels, masked_pos\n","\n","import pickle\n","\n","with open(\"/content/drive/MyDrive/recsys/bert/full_data/bert_train.pkl\", \"rb\") as fh:\n","    train_sequences = pickle.load(fh)\n","\n","\n","\n","\n","max_item_id = max(el for seq in train_sequences for el in seq)  # Since you start enumeration from 1\n","VOCAB_SIZE = max_item_id + 2   # +1 for PAD (0), +1 for MASK\n","MASK_ID = VOCAB_SIZE - 1\n","PAD_ID = 0\n","MAX_SEQUENCE_LEN = 128\n","\n","NUM_EPOCHS = 5\n","\n","print(f\"Unique items count: {max_item_id}\")\n","print(f\"Max item ID in sequences: {max(el for seq in train_sequences for el in seq)}\")\n","print(f\"Min item ID in sequences: {min(el for seq in train_sequences for el in seq)}\")\n","print(f\"VOCAB_SIZE: {VOCAB_SIZE}\")\n","print(f\"MASK_ID: {MASK_ID}\")\n","\n","train_size = int(0.99 * len(train_sequences))\n","val_size = len(train_sequences) - train_size\n","\n","train_dataset, val_dataset = random_split(train_sequences, [train_size, val_size])\n","\n","len(train_dataset) // 256\n","\n","train_loader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=16,\n","    shuffle=True,\n","    collate_fn=lambda batch: collate_fn(batch, mask_token_id=MASK_ID, vocab_size=VOCAB_SIZE, max_len=MAX_SEQUENCE_LEN),\n",")\n","\n","val_loader = DataLoader(\n","    dataset=val_dataset,\n","    batch_size=16,\n","    shuffle=False,\n","    collate_fn=lambda batch: collate_fn(batch, mask_token_id=MASK_ID, vocab_size=VOCAB_SIZE, max_len=MAX_SEQUENCE_LEN),\n",")\n","\n","config = BERT4RecConfig(\n","    vocab_size=VOCAB_SIZE,\n","    embedding_dim=256,\n","    max_seq_len=MAX_SEQUENCE_LEN,\n","    embedding_dropout=0.2,\n","    num_layers=6,\n","    num_heads=8,\n","    hidden_dim=256,\n","    encoder_dropout=0.2,\n","    projection_dim=256,\n",")\n","\n","\n","model = BERT4Rec(config)\n","model = model.to(DEVICE)\n","optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n","\n","def evaluate(model, val_loader):\n","    model.eval()\n","    total_loss = 0.0\n","    total_hr10 = 0.0\n","    total_ndcg10 = 0.0\n","    total_batches = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            val_loss, hr10, ndcg10 = validate_step(model, batch)\n","            total_loss += val_loss\n","            total_hr10 += hr10\n","            total_ndcg10 += ndcg10\n","            total_batches += 1\n","\n","    return (\n","        total_loss / total_batches,\n","        total_hr10 / total_batches,\n","        total_ndcg10 / total_batches\n","    )\n","\n","train_history = []\n","valid_history = []\n","\n","NUM_EPOCHS = 5\n","for epoch in range(NUM_EPOCHS):\n","    for step, batch in enumerate(tqdm.tqdm(train_loader, desc=\"Training\")):\n","        loss = train_step(model, optimizer, batch)\n","        train_history.append(loss)\n","        if step % 1000 == 0 and step != 0:\n","            print(f\"\\nstep {step} loss {np.mean(train_history[-1000:])}\")\n","        if step % 5000 == 0 and step != 0:\n","            val_loss, hr10, ndcg10 = validate_step(model, next(iter(val_loader)))\n","            valid_history.append((val_loss, hr10, ndcg10))\n","            print(f\"\\nEpoch {epoch + 1} | Val Loss: {val_loss:.4f} | HR@10: {hr10:.4f} | NDCG@10: {ndcg10:.4f}\")\n","            if val_loss == min(valid_history, key=lambda x: x[0])[0]:\n","              torch.save({\n","    'model_state_dict': model.state_dict(),\n","    'optimizer_state_dict': optimizer.state_dict(),\n","    'config': config\n","}, '/content/drive/MyDrive/recsys/bert/full_data/bert4rec_model_512dim_bigger_30seqlen_pagevisit.pt')\n","\n","    scheduler.step()\n","\n","import torch\n","import numpy as np\n","import pickle\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","\n","# Load the saved model\n","print(\"Loading model...\")\n","checkpoint = torch.load('/content/drive/MyDrive/recsys/bert/full_data/bert4rec_model_512dim_bigger_30seqlen_buys.pt', weights_only=False)\n","\n","# Initialize model with saved config\n","model = BERT4Rec(checkpoint['config'])\n","model.load_state_dict(checkpoint['model_state_dict'])\n","\n","# Move to device and set to eval mode\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(DEVICE)\n","model.eval()\n","\n","print(\"Model loaded successfully!\")\n","\n","# Get configuration\n","PAD = 0\n","max_len = MAX_SEQUENCE_LEN\n","\n","# Load and filter data\n","print(\"Loading training data...\")\n","with open(\"/content/drive/MyDrive/recsys/bert/full_data/buys_bert_train.pkl\", \"rb\") as fh:\n","    train_sequences = pickle.load(fh)\n","\n","with open(\"/content/drive/MyDrive/recsys/bert/full_data/buys_clients_train.pkl\", \"rb\") as fh:\n","    clients = pickle.load(fh)\n","\n","from collections import Counter\n","\n","# Step 1: Count ID occurrences\n","counts = Counter(id for sublist in train_sequences for id in sublist)\n","\n","# Step 2: Select IDs that appear >= 50 times\n","common_ids = {id for id, count in counts.items() if count >= 10}\n","\n","# Step 3: Filter original data to keep only frequent IDs\n","filtered_data = [\n","    [id for id in sublist if id in common_ids]\n","    for sublist in train_sequences\n","]\n","\n","# Step 4: Build mapping to dense IDs starting from 1\n","# Sorted for reproducibility (optional)\n","unique_ids = sorted(common_ids)\n","id_to_dense = {old_id: new_id for new_id, old_id in enumerate(unique_ids, start=1)}\n","\n","# Step 5: Apply mapping\n","train_sequences = [\n","    [id_to_dense[id] for id in sublist]\n","    for sublist in filtered_data\n","]\n","\n","relevant_clients = np.load(\"/content/drive/MyDrive/recsys/original_data/input/relevant_clients.npy\")\n","\n","print(f\"Total sequences: {len(train_sequences)}\")\n","print(f\"Relevant clients: {len(relevant_clients)}\")\n","\n","# Convert to sets for efficient lookup\n","relevant_client_set = set(relevant_clients)\n","available_client_set = set(clients)\n","\n","# Find clients that are in relevant_clients but not in available clients\n","missing_clients = relevant_client_set - available_client_set\n","print(f\"Missing clients (in relevant but not in training): {len(missing_clients)}\")\n","\n","# Filter sequences for relevant clients that exist in training data\n","filtered_data = []\n","filtered_client_ids = []\n","\n","for i, client in enumerate(clients):\n","    if client in relevant_client_set:\n","        filtered_data.append(train_sequences[i])\n","        filtered_client_ids.append(client)\n","\n","print(f\"Filtered sequences with data: {len(filtered_data)}\")\n","\n","# Pad sequences and create attention masks\n","def pad_sequence_to_length(sequence, target_length, pad_value=PAD):\n","    if len(sequence) >= target_length:\n","        return sequence[:target_length]\n","    else:\n","        return sequence + [pad_value] * (target_length - len(sequence))\n","\n","padded_sequences = []\n","attention_masks = []\n","\n","for seq in filtered_data:\n","    padded_seq = pad_sequence_to_length(seq, max_len, PAD)\n","    mask = [1 if token != PAD else 0 for token in padded_seq]\n","    padded_sequences.append(padded_seq)\n","    attention_masks.append(mask)\n","\n","# Generate embeddings for clients with data\n","print(\"Generating embeddings for clients with data...\")\n","batch_size = 512\n","computed_embeddings = []\n","\n","if len(filtered_data) > 0:\n","    padded_tensor = torch.tensor(padded_sequences, dtype=torch.long)\n","    mask_tensor = torch.tensor(attention_masks, dtype=torch.float)\n","    dataset = TensorDataset(padded_tensor, mask_tensor)\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","    def mean_pooling(embeddings, attention_mask):\n","        \"\"\"Apply mean pooling with attention mask to ignore padding tokens\"\"\"\n","        mask_expanded = attention_mask.unsqueeze(-1).expand(embeddings.size())\n","        sum_embeddings = torch.sum(embeddings * mask_expanded, dim=1)\n","        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n","        return sum_embeddings / sum_mask\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_idx, (batch_sequences, batch_masks) in enumerate(dataloader):\n","            batch_sequences = batch_sequences.to(DEVICE)\n","            batch_masks = batch_masks.to(DEVICE)\n","\n","            embeddings = model.embedding(batch_sequences)\n","            embeddings = model.encoder(embeddings)\n","\n","            pooled_embeddings = mean_pooling(embeddings, batch_masks)\n","            pooled_embeddings = pooled_embeddings.cpu().numpy().astype(np.float16)\n","            computed_embeddings.append(pooled_embeddings)\n","\n","            if (batch_idx + 1) % 10 == 0:\n","                print(f\"Processed {(batch_idx + 1) * batch_size} sequences...\")\n","\n","    computed_embeddings = np.concatenate(computed_embeddings, axis=0)\n","else:\n","    computed_embeddings = np.empty((0, 64), dtype=np.float16)\n","\n","print(f\"Computed embeddings shape: {computed_embeddings.shape}\")\n","\n","# Create complete embeddings array for all relevant clients\n","print(\"Creating complete embeddings array...\")\n","\n","# Sort relevant clients for consistent ordering\n","sorted_relevant_clients = np.sort(relevant_clients)\n","\n","# Create mapping from client_id to embedding\n","client_to_embedding = {}\n","for i, client_id in enumerate(filtered_client_ids):\n","    client_to_embedding[client_id] = computed_embeddings[i]\n","\n","# Create final arrays\n","final_embeddings = []\n","final_client_ids = []\n","\n","for client_id in sorted_relevant_clients:\n","    final_client_ids.append(client_id)\n","\n","    if client_id in client_to_embedding:\n","        # Use computed embedding\n","        final_embeddings.append(client_to_embedding[client_id])\n","    else:\n","        # Use zero embedding for missing clients\n","        zero_embedding = np.zeros(256, dtype=np.float16)\n","        final_embeddings.append(zero_embedding)\n","\n","# Convert to numpy arrays\n","final_embeddings = np.array(final_embeddings, dtype=np.float16)\n","final_client_ids = np.array(final_client_ids, dtype=np.int64)\n","\n","print(f\"Final embeddings shape: {final_embeddings.shape}\")\n","print(f\"Final client IDs shape: {final_client_ids.shape}\")\n","print(f\"Clients with computed embeddings: {len(filtered_client_ids)}\")\n","print(f\"Clients with zero embeddings: {len(missing_clients)}\")\n","print(f\"Total clients: {len(final_client_ids)}\")\n","\n","# Verify all relevant clients are included\n","assert len(final_client_ids) == len(relevant_clients), \"Mismatch in client count!\"\n","assert set(final_client_ids) == set(relevant_clients), \"Client sets don't match!\"\n","\n","# Save the results\n","print(\"Saving complete embeddings and client IDs...\")\n","np.save('/content/drive/MyDrive/recsys/bert/full_data/embeddings_512dim_bigger_30seqlen_buys.npy', final_embeddings)\n","np.save('/content/drive/MyDrive/recsys/bert/full_data/client_ids_512dim_bigger_30seqlen_buys.npy', final_client_ids)\n","\n","print(\"Complete embeddings generation finished!\")\n","print(f\"Final shape: [{len(final_client_ids)}, {64}]\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":533},"id":"-6Y-MTQXQ5m_","executionInfo":{"status":"error","timestamp":1749227768318,"user_tz":-120,"elapsed":77588,"user":{"displayName":"Adam Stajek","userId":"09534021670324781377"}},"outputId":"b4907cf1-b1c9-42dc-fdd9-fda71be5a16e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Working on DEVICE=device(type='cpu')\n","Unique items count: 1495777\n","Max item ID in sequences: 1495777\n","Min item ID in sequences: 4\n","VOCAB_SIZE: 1495779\n","MASK_ID: 1495778\n"]},{"output_type":"stream","name":"stderr","text":["Training:   0%|          | 1/46460 [00:22<294:56:22, 22.85s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-593ffc87e845>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-593ffc87e845>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, batch, device)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    876\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdevice_beta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"YAdUVVSeQ8Dd","executionInfo":{"status":"aborted","timestamp":1749227768314,"user_tz":-120,"elapsed":77701,"user":{"displayName":"Adam Stajek","userId":"09534021670324781377"}}},"execution_count":null,"outputs":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":7366643,"sourceId":11734888,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[{"file_id":"1ioJaDyQDL3Af2NLYjkL_eOHKmWfO1_2a","timestamp":1748716833981}],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":0}