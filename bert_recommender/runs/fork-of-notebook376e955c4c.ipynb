{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11734888,"sourceType":"datasetVersion","datasetId":7366643}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"TOTAL_ITEM_COUNT = 1495777 # 1495778\nVOCAB_SIZE = TOTAL_ITEM_COUNT + 2  # including PAD and MASK\nMASK_ID = VOCAB_SIZE - 1  # Add special token for [MASK]\nPAD_ID = 0\nMAX_SEQUENCE_LEN = 8\n\nNUM_EPOCHS = 1 \nimport random\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\n\nimport pickle\nimport torch\nimport tqdm\nfrom torch import optim\nfrom torch.utils.data import DataLoader, random_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:25.592058Z","iopub.execute_input":"2025-05-08T15:31:25.592287Z","iopub.status.idle":"2025-05-08T15:31:29.564860Z","shell.execute_reply.started":"2025-05-08T15:31:25.592263Z","shell.execute_reply":"2025-05-08T15:31:29.564195Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Working on {DEVICE=}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.566717Z","iopub.execute_input":"2025-05-08T15:31:29.567040Z","iopub.status.idle":"2025-05-08T15:31:29.626078Z","shell.execute_reply.started":"2025-05-08T15:31:29.567021Z","shell.execute_reply":"2025-05-08T15:31:29.624984Z"}},"outputs":[{"name":"stdout","text":"Working on DEVICE=device(type='cuda')\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom dataclasses import dataclass\n\n\n# GPT said this is a professional way to do it\n@dataclass\nclass BERT4RecConfig:\n    # EmbeddingLayer\n    vocab_size: int\n    embedding_dim: int\n    max_seq_len: int\n    embedding_dropout: float\n\n    # Encoder\n    num_layers: int\n    num_heads: int\n    hidden_dim: int\n    encoder_dropout: float\n\n    # ProjectionHead\n    projection_dim: int\n\n\nclass EmbeddingLayer(nn.Module):\n    \"\"\"Item + positional embeddings with layer normalization and dropout\"\"\"\n\n    def __init__(self, vocab_size: int, embedding_dim: int, max_seq_len: int, dropout: float = 0.1):\n        super().__init__()\n        self.item_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.position_embeddings = nn.Embedding(max_seq_len, embedding_dim)\n        self.layer_norm = nn.LayerNorm(embedding_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.vocab_size = vocab_size\n\n    def forward(self, x):\n        positions = torch.arange(x.size(1), device=x.device).unsqueeze(0).expand_as(x)\n        # print(x.max(), self.vocab_size, x.min())\n        embeddings = self.item_embeddings(x) + self.position_embeddings(positions)\n        embeddings = self.layer_norm(embeddings)\n        return self.dropout(embeddings)\n\n\nclass Encoder(nn.Module):\n    \"\"\"Transformer encoder. Wrapper for `torch.TransformerEncoderLayer`\"\"\"\n\n    def __init__(self, embedding_dim: int, num_layers: int, num_heads: int, hidden_dim: int,\n                 dropout: float = 0.1) -> None:\n        \"\"\"\n\n        Args:\n            embedding_dim:\n            num_layers:\n            num_heads:\n            hidden_dim:\n            dropout:\n\n        Returns:\n            None:\n        \"\"\"\n        super().__init__()\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embedding_dim,\n            nhead=num_heads,\n            dim_feedforward=hidden_dim,\n            dropout=dropout,\n            activation=\"gelu\",\n            batch_first=True,\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n\n    def forward(self, x, src_key_padding_mask=None):\n        # x: [batch_size, seq_len, embedding_dim]\n        return self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n\n\nclass ProjectionHead(nn.Module):\n    \"\"\"Projection head\"\"\"\n\n    def __init__(self, embedding_dim: int, projection_dim: int, vocab_size: int):\n        super().__init__()\n        # transform + layer normalization\n        self.projection = nn.Linear(embedding_dim, projection_dim)\n        self.activation = nn.GELU()\n        self.layer_norm = nn.LayerNorm(projection_dim)\n\n        # map to final logits\n        self.decoder = nn.Linear(projection_dim, vocab_size, bias=False)\n        self.bias = nn.Parameter(torch.zeros(vocab_size))\n\n    def forward(self, x):\n        # x: [batch_size, seq_len, embedding_dim]\n        proj = self.projection(x)\n        proj = self.activation(proj)\n        proj = self.layer_norm(proj)\n        return self.decoder(proj) + self.bias\n\n\nclass BERT4Rec(nn.Module):\n    \"\"\"BERT4Rec model from `https://arxiv.org/pdf/1904.06690` paper\"\"\"\n\n    def __init__(self, config: BERT4RecConfig):\n        super().__init__()\n        self.embedding = EmbeddingLayer(\n            vocab_size=config.vocab_size,\n            embedding_dim=config.embedding_dim,\n            max_seq_len=config.max_seq_len,\n            dropout=config.embedding_dropout,\n        )\n        self.encoder = Encoder(\n            embedding_dim=config.embedding_dim,\n            num_layers=config.num_layers,\n            num_heads=config.num_heads,\n            hidden_dim=config.hidden_dim,\n            dropout=config.encoder_dropout,\n        )\n        self.projection = ProjectionHead(\n            embedding_dim=config.embedding_dim,\n            projection_dim=config.projection_dim,\n            vocab_size=config.vocab_size,\n        )\n\n        # weights sharing\n        self.projection.decoder.weight = self.embedding.item_embeddings.weight\n\n    def forward(self, x, mask=None):\n        pad_mask = x.eq(0)\n        x = self.embedding(x)\n        x = self.encoder(x, src_key_padding_mask=pad_mask)\n        x = self.projection(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.627711Z","iopub.execute_input":"2025-05-08T15:31:29.627965Z","iopub.status.idle":"2025-05-08T15:31:29.649514Z","shell.execute_reply.started":"2025-05-08T15:31:29.627946Z","shell.execute_reply":"2025-05-08T15:31:29.648723Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def masked_cross_entropy_loss(logits, labels, mask):\n    \"\"\"\n    Args:\n        logits: [batch_size, seq_len, vocab_size] - output from model\n        labels: [batch_size, seq_len] - ground truth item IDs (masked positions are real, others are 0 or ignored)\n        mask:   [batch_size, seq_len] - binary mask indicating which positions are masked (1 = predict, 0 = ignore)\n    Returns:\n        scalar loss\n    \"\"\"\n    logits = logits.view(-1, logits.size(-1))  # [B*L, V]\n    labels = labels.view(-1)  # [B*L]\n    mask = mask.view(-1).float()  # [B*L]\n\n    # Compute per-position loss, but ignore non-masked tokens (mask == 0)\n    loss = F.cross_entropy(logits, labels, reduction='none')  # [B*L]\n    masked_loss = loss * mask\n    return masked_loss.sum() / mask.sum()\n\n\ndef train_step(model, optimizer, batch, device=DEVICE):\n    model.train()\n    input_ids, labels, masked_pos = [x.to(device) for x in batch]  # all [B, L]\n\n    optimizer.zero_grad()\n    logits = model(input_ids)  # [B, L, V]\n    loss = masked_cross_entropy_loss(logits, labels, masked_pos)\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()\n\n\ndef validate_step(model, batch, top_k=10, device=DEVICE):\n    model.eval()\n    input_ids, labels, masked_pos = [x.to(device) for x in batch]\n\n    with torch.no_grad():\n        logits = model(input_ids)  # [B, L, V]\n\n    # Only consider predictions at masked positions\n    masked_logits = logits[masked_pos.bool()]  # [N_masked, V]\n    masked_labels = labels[masked_pos.bool()]  # [N_masked]\n\n    loss = F.cross_entropy(masked_logits, masked_labels, reduction='mean').item()\n\n    # HR@10 and NDCG@10\n    _, topk = masked_logits.topk(top_k, dim=-1)  # [N, top_k]\n    hits = (topk == masked_labels.unsqueeze(1)).float()  # [N, top_k]\n    hr = hits.any(dim=1).float().mean().item()\n    ndcg = (hits / torch.log2(torch.arange(2, top_k + 2, device=hits.device).float())).sum(dim=1).mean().item()\n\n    return loss, hr, ndcg\n\n\ndef mask_sequence(seq, mask_token_id, vocab_size, mask_prob=0.15, pad_token_id=0):\n    \"\"\"\n    Function takes a user sequence and randomly selects items to mask.\n    Returns:\n        - input_ids: modified sequence with [MASK] and others.\n        - labels: target items only in masked positions (0 elsewhere).\n        - masked_pos: binary mask of masked locations.\n    \"\"\"\n    input_ids = seq.copy()\n    labels = [0] * len(seq)\n    masked_pos = [0] * len(seq)\n    # mask_prob = 0.5\n\n    for i in range(len(seq)):\n        if seq[i] == pad_token_id:\n            continue\n        if random.random() < mask_prob:\n            masked_pos[i] = 1\n            labels[i] = seq[i]\n            rand = random.random()\n            if rand < 0.8:\n                input_ids[i] = mask_token_id\n            elif rand < 0.9:\n                input_ids[i] = random.randint(1, vocab_size - 1)  # avoid pad token\n            else:\n                pass  # leave unchanged\n    return input_ids, labels, masked_pos\n\n\ndef collate_fn(batch, mask_token_id, vocab_size, pad_token_id=0, max_len=None):\n    \"\"\"\n    Pads sequences to same length, converts everything to tensors.\n    batch: list of sequences (list of item IDs)\n    \"\"\"\n    input_ids, labels, masked_pos = [], [], []\n\n    for seq in batch:\n        if max_len is not None:\n            seq = seq[-max_len:]  # truncate if needed\n\n        inp, lab, msk = mask_sequence(seq, mask_token_id, vocab_size, pad_token_id=pad_token_id)\n        input_ids.append(torch.tensor(inp))\n        labels.append(torch.tensor(lab))\n        masked_pos.append(torch.tensor(msk))\n\n    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=pad_token_id)\n    labels = pad_sequence(labels, batch_first=True, padding_value=0)\n    masked_pos = pad_sequence(masked_pos, batch_first=True, padding_value=0)\n\n    return input_ids, labels, masked_pos","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.650327Z","iopub.execute_input":"2025-05-08T15:31:29.650594Z","iopub.status.idle":"2025-05-08T15:31:29.671986Z","shell.execute_reply.started":"2025-05-08T15:31:29.650572Z","shell.execute_reply":"2025-05-08T15:31:29.671217Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"TOTAL_ITEM_COUNT = 1495777 # 1495778\nVOCAB_SIZE = TOTAL_ITEM_COUNT + 2  # including PAD and MASK\nMASK_ID = VOCAB_SIZE - 1  # Add special token for [MASK]\nPAD_ID = 0\nMAX_SEQUENCE_LEN = 8\n\nNUM_EPOCHS = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.672827Z","iopub.execute_input":"2025-05-08T15:31:29.673079Z","iopub.status.idle":"2025-05-08T15:31:29.689995Z","shell.execute_reply.started":"2025-05-08T15:31:29.673058Z","shell.execute_reply":"2025-05-08T15:31:29.689252Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import pickle \n\nwith open(\"/kaggle/input/agh-sp2/bert_train_corrected.pkl\", \"rb\") as fh:\n    train_sequences = pickle.load(fh)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.690815Z","iopub.execute_input":"2025-05-08T15:31:29.691105Z","iopub.status.idle":"2025-05-08T15:31:29.884468Z","shell.execute_reply.started":"2025-05-08T15:31:29.691081Z","shell.execute_reply":"2025-05-08T15:31:29.883719Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_size = int(0.8 * len(train_sequences))\nval_size = len(train_sequences) - train_size\n\ntrain_dataset, val_dataset = random_split(train_sequences, [train_size, val_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.886851Z","iopub.execute_input":"2025-05-08T15:31:29.887068Z","iopub.status.idle":"2025-05-08T15:31:29.917228Z","shell.execute_reply.started":"2025-05-08T15:31:29.887051Z","shell.execute_reply":"2025-05-08T15:31:29.916395Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"len(train_dataset) // 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.918119Z","iopub.execute_input":"2025-05-08T15:31:29.918398Z","iopub.status.idle":"2025-05-08T15:31:29.924422Z","shell.execute_reply.started":"2025-05-08T15:31:29.918373Z","shell.execute_reply":"2025-05-08T15:31:29.923714Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"301"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=256,\n    shuffle=True,\n    collate_fn=lambda batch: collate_fn(batch, mask_token_id=MASK_ID, vocab_size=VOCAB_SIZE, max_len=MAX_SEQUENCE_LEN),\n)\n\nval_loader = DataLoader(\n    dataset=val_dataset,\n    batch_size=256,\n    shuffle=False,\n    collate_fn=lambda batch: collate_fn(batch, mask_token_id=MASK_ID, vocab_size=VOCAB_SIZE),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.925253Z","iopub.execute_input":"2025-05-08T15:31:29.925608Z","iopub.status.idle":"2025-05-08T15:31:29.940596Z","shell.execute_reply.started":"2025-05-08T15:31:29.925584Z","shell.execute_reply":"2025-05-08T15:31:29.939682Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import gc\n\ndef cleanup_cuda():\n    gc.collect()\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.941415Z","iopub.execute_input":"2025-05-08T15:31:29.941690Z","iopub.status.idle":"2025-05-08T15:31:29.957452Z","shell.execute_reply.started":"2025-05-08T15:31:29.941668Z","shell.execute_reply":"2025-05-08T15:31:29.956904Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"cleanup_cuda()\ncleanup_cuda()\ncleanup_cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:29.958371Z","iopub.execute_input":"2025-05-08T15:31:29.958651Z","iopub.status.idle":"2025-05-08T15:31:30.317944Z","shell.execute_reply.started":"2025-05-08T15:31:29.958630Z","shell.execute_reply":"2025-05-08T15:31:30.317171Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"config = BERT4RecConfig(\n    vocab_size=VOCAB_SIZE + 2,\n    embedding_dim=64,\n    max_seq_len=MAX_SEQUENCE_LEN,\n    embedding_dropout=0.2,\n    num_layers=8,\n    num_heads=8,\n    hidden_dim=128,\n    encoder_dropout=0.2,\n    projection_dim=64,\n)\n\nmodel = BERT4Rec(config)\nmodel = model.to(DEVICE)\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:30.318840Z","iopub.execute_input":"2025-05-08T15:31:30.319116Z","iopub.status.idle":"2025-05-08T15:31:34.590098Z","shell.execute_reply.started":"2025-05-08T15:31:30.319090Z","shell.execute_reply":"2025-05-08T15:31:34.589335Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_history = []\nvalid_history = []\n\nNUM_EPOCHS = 5\nfor epoch in range(NUM_EPOCHS):\n    for batch in tqdm.tqdm(train_loader, desc=\"Training\"):\n        loss = train_step(model, optimizer, batch)\n        train_history.append(loss)\n    \n    val_loss, hr10, ndcg10 = validate_step(model, next(iter(val_loader)))\n    valid_history.append((val_loss, hr10, ndcg10))\n    print(f\"Epoch {epoch + 1} | Val Loss: {val_loss:.4f} | HR@10: {hr10:.4f} | NDCG@10: {ndcg10:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:34.590870Z","iopub.execute_input":"2025-05-08T15:31:34.591237Z","iopub.status.idle":"2025-05-08T15:31:35.085293Z","shell.execute_reply.started":"2025-05-08T15:31:34.591211Z","shell.execute_reply":"2025-05-08T15:31:35.084189Z"}},"outputs":[{"name":"stderr","text":"Training:   0%|          | 0/302 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/953775434.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1055607957.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, batch, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, L, V]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_cross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1092743994.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1092743994.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 11.41 GiB. GPU 0 has a total capacity of 15.89 GiB of which 3.74 GiB is free. Process 5924 has 12.15 GiB memory in use. Of the allocated memory 11.84 GiB is allocated by PyTorch, and 15.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 11.41 GiB. GPU 0 has a total capacity of 15.89 GiB of which 3.74 GiB is free. Process 5924 has 12.15 GiB memory in use. Of the allocated memory 11.84 GiB is allocated by PyTorch, and 15.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef moving_average(data, window_size):\n    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n\nwindow_size = 100\ny = moving_average(train_history, window_size)\nx = np.arange(len(y)) + window_size\n\nplt.plot(x, y, color='blue', alpha=0.5, label='train loss')\nplt.axhline(val_loss, color='black', linestyle='--', label='val loss')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:31:35.085950Z","iopub.status.idle":"2025-05-08T15:31:35.086173Z","shell.execute_reply.started":"2025-05-08T15:31:35.086071Z","shell.execute_reply":"2025-05-08T15:31:35.086081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}